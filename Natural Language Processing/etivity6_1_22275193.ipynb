{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Etivity 6.1\n",
        "\n",
        "Dara Corr - 22275193"
      ],
      "metadata": {
        "id": "T1zbqu1CHEE1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Task 1:\n",
        "given the two confusion tables below,\n",
        "\n",
        "$\\textbf{Class Food}$\n",
        "\n",
        "\\begin{array} {|r|r|}\\hline  & \\text{Truth: YES} & \\text{Truth: NO} \\\\ \\hline \\text{Classifier: YES} & 800 & 200 \\\\ \\hline \\text{Classifier: NO} & 200 & 500 \\\\ \\hline  \\end{array}\n",
        "\n",
        "$\\textbf{Class Drink}$\n",
        "\n",
        "\\begin{array} {|r|r|}\\hline  & \\text{Truth: YES} & \\text{Truth: NO} \\\\ \\hline \\text{Classifier: YES} & 70 & 30 \\\\ \\hline \\text{Classifier: NO} & 30 & 100 \\\\ \\hline  \\end{array}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " calculate:\n",
        "\n",
        "a) Microaveraged precision, recall, and F1\n",
        "\n",
        "b) Macroaveraged precision, recall, and F1\n",
        "\n",
        "c) Explain the reason for the difference between the obtained Microaveraged and Macroaveraged F1 measures.\n",
        "\n",
        "\\\n",
        "Using formulae:\n",
        "\n",
        "Precision = $\\frac{tp}{tp + fp}$\n",
        "\n",
        "Recall = $\\frac{tp}{tp + fn}$\n",
        "\n",
        "F1 = $\\frac{2PR}{P+R}$\n",
        "\n",
        "\n",
        "\n",
        "\\\n",
        "\n",
        "a) Microaveraged\n",
        "\\\n",
        "\\begin{array} {|r|r|}\\hline  & \\text{Truth: YES} & \\text{Truth: NO} \\\\ \\hline \\text{Classifier: YES} & 870 & 230 \\\\ \\hline \\text{Classifier: NO} & 230 & 600 \\\\ \\hline  \\end{array}\n",
        "\n",
        "Microaveraged Precision = $\\frac{870}{870 + 230} = \\frac{870}{1100} = 0.79091 = 79.091\\% $\n",
        "\n",
        "Microaveraged Recall =  $\\frac{870}{870 + 230} = \\frac{870}{1100} = 0.79091 = 79.091\\% $\n",
        "\n",
        "F1 = $\\frac{(2) \\cdot (0.79091) \\cdot (0.79091)}{0.79091 + 0.79091} = \\frac{2 \\cdot (0.79091)^2}{2(0.79091)} = 0.79091 = 79.091\\% $ \n",
        "\n",
        "\n",
        "\\\n",
        "b) Macroaveraged\n",
        "\n",
        "\n",
        "Macroaveraged Precision = $\\frac{800/1000 + 70/100}{2} = \\frac{0.8+0.7}{2} = 0.75 = 75.0\\% $\n",
        "\n",
        "Macroaveraged Recall =  $\\frac{800/1000 + 70/100}{2} = \\frac{0.8+0.7}{2} = 0.75 = 75.0\\% $\n",
        "\n",
        "F1 = $\\frac{(2) \\cdot (0.75) \\cdot (0.75)}{0.75 + 0.75} = \\frac{2 \\cdot (0.75)^2}{2(0.75)} = 0.75 = 75.0\\% $ \n",
        "\n",
        "\\\n",
        "c) The difference between microaveraged and macroaveraged values is because the Microaveraged score is donimated by score of the common classes (The Food Class dominates here, as it is most common). With microaveraging, each class participates equally when being averaged.\n"
      ],
      "metadata": {
        "id": "3xqRwHZLHLW3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6LL94BZ9HCMh"
      },
      "outputs": [],
      "source": [
        "#Task 2\n",
        "\n",
        "def NaiveBayes(trainingset,testset):\n",
        "\n",
        "  testingSetLower = [(doc[0].lower(), doc[1].lower()) for doc in testset] ########## <- From Conor Pesch\n",
        "\n",
        "\n",
        "  #calc priors and create bag of words\n",
        "  PLUScount = 0\n",
        "  NEGcount = 0\n",
        "\n",
        "  WORDS_classPLUS = []\n",
        "  WORDS_classNEG = []\n",
        "\n",
        "  for i in range(len(trainingset)):\n",
        "    if trainingSet[i][1] == \"-\":\n",
        "      WORDS_classNEG.append((trainingSet[i][0].lower()))\n",
        "      NEGcount +=1\n",
        "\n",
        "    if trainingSet[i][1] == \"+\":\n",
        "      WORDS_classPLUS.append((trainingSet[i][0].lower()))\n",
        "      PLUScount +=1\n",
        "\n",
        "  probPLUS = PLUScount/len(trainingset) #initialise probabilities as prior probabilities\n",
        "  probNEG = NEGcount/len(trainingset)\n",
        " \n",
        "  print(f'prob+ = {probPLUS}, prob- = {probNEG}\\n') ################New line from Conor Pesch\n",
        "\n",
        "  WORDS_classNEG = (\" \".join(WORDS_classNEG)).split(\" \")\n",
        "  WORDS_classPLUS = (\" \".join(WORDS_classPLUS)).split(\" \")#bag of words as list\n",
        "\n",
        "  #make bag of words as dict with counts\n",
        "  BOW_PLUS = {}\n",
        "  BOW_NEG = {}\n",
        "\n",
        "  for word in WORDS_classPLUS:\n",
        "    if word not in BOW_PLUS:\n",
        "      BOW_PLUS[word] = 1\n",
        "    else:\n",
        "      BOW_PLUS[word] += 1\n",
        "\n",
        "  for word in WORDS_classNEG:\n",
        "    if word not in BOW_NEG:\n",
        "      BOW_NEG[word] = 1\n",
        "    else:\n",
        "      BOW_NEG[word] += 1\n",
        "          \n",
        "\n",
        "  print(BOW_PLUS)\n",
        "  print(BOW_NEG)\n",
        "\n",
        "  def Merge(dict1, dict2): \n",
        "    res = {**dict1, **dict2}\n",
        "    return res\n",
        "\n",
        "  VOCAB = Merge(BOW_PLUS,BOW_NEG) #vocab\n",
        "  V = len(VOCAB) #size of vocab\n",
        "\n",
        "  print(f'V = {VOCAB}\\n|V| = {V}\\n')\n",
        "\n",
        "  ############### new code below #################\n",
        "  \n",
        "   # iterate through docs in testing set\n",
        "  for i, doc in enumerate(testingSetLower):\n",
        "    print(\"--------------------------------------------------\")\n",
        "    print(f\"Test Document = {testset[i]}\\n\")\n",
        "\n",
        "    # find conditional probabilities for each word in testing doc\n",
        "    wordConditionalProbNEG = {}\n",
        "    wordConditionalProbPLUS = {}\n",
        "\n",
        "    for word in doc[0].split():\n",
        "      if word in BOW_NEG.keys():\n",
        "        wordConditionalProbNEG[word] = (BOW_NEG[word]+1)/(len(BOW_NEG)+V)\n",
        "      else:\n",
        "        wordConditionalProbNEG[word] = (1)/(len(BOW_NEG)+V)\n",
        "\n",
        "      if word in BOW_PLUS.keys():\n",
        "        wordConditionalProbPLUS[word] = (BOW_PLUS[word]+1)/(len(BOW_PLUS)+V)\n",
        "      else:\n",
        "        wordConditionalProbPLUS[word] = (1)/(len(BOW_PLUS)+V)\n",
        "\n",
        "      print(f'word = \"{word:15}\",     wordConditionalProb- = {wordConditionalProbNEG[word]:.15},     wordConditionalProb+ = {wordConditionalProbPLUS[word]:.15}')\n",
        "\n",
        "    # find class probabilities\n",
        "    docProbNEG = probNEG * sum(list(wordConditionalProbNEG.values())) #update probabilities with conditional probabilities\n",
        "    docProbPLUS = probPLUS * sum(list(wordConditionalProbPLUS.values())) #\n",
        "\n",
        "    print(f'\\ndocProb- = {docProbNEG}, docProb+ = {docProbPLUS}')\n",
        "\n",
        "    # determine class\n",
        "    if docProbNEG > docProbPLUS:\n",
        "      print('Inferred class = Negative (-)')\n",
        "    elif docProbPLUS > docProbNEG:\n",
        "      print('Inferred class = Positive (+)')\n",
        "    else:\n",
        "      print('Inferred class = Positive/Negative (+/-)')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainingSet = [('just plain boring','-'),('entirely predictable and lacks energy','-'),('no surprises and very few laughs','-'),('very powerful','+'),('the most fun film of the summer','+')]\n",
        "testSet = [('predictable with no fun','?')]\n",
        "\n",
        "NaiveBayes(trainingSet,testSet)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ws-Qk-zI_D7w",
        "outputId": "81f412bb-a995-423a-bfab-6231e54bb9a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prob+ = 0.4, prob- = 0.6\n",
            "\n",
            "{'very': 1, 'powerful': 1, 'the': 2, 'most': 1, 'fun': 1, 'film': 1, 'of': 1, 'summer': 1}\n",
            "{'just': 1, 'plain': 1, 'boring': 1, 'entirely': 1, 'predictable': 1, 'and': 2, 'lacks': 1, 'energy': 1, 'no': 1, 'surprises': 1, 'very': 1, 'few': 1, 'laughs': 1}\n",
            "V = {'very': 1, 'powerful': 1, 'the': 2, 'most': 1, 'fun': 1, 'film': 1, 'of': 1, 'summer': 1, 'just': 1, 'plain': 1, 'boring': 1, 'entirely': 1, 'predictable': 1, 'and': 2, 'lacks': 1, 'energy': 1, 'no': 1, 'surprises': 1, 'few': 1, 'laughs': 1}\n",
            "|V| = 20\n",
            "\n",
            "--------------------------------------------------\n",
            "Test Document = ('predictable with no fun', '?')\n",
            "\n",
            "word = \"predictable    \",     wordConditionalProb- = 0.0606060606060606,     wordConditionalProb+ = 0.0357142857142857\n",
            "word = \"with           \",     wordConditionalProb- = 0.0303030303030303,     wordConditionalProb+ = 0.0357142857142857\n",
            "word = \"no             \",     wordConditionalProb- = 0.0606060606060606,     wordConditionalProb+ = 0.0357142857142857\n",
            "word = \"fun            \",     wordConditionalProb- = 0.0303030303030303,     wordConditionalProb+ = 0.0714285714285714\n",
            "\n",
            "docProb- = 0.10909090909090909, docProb+ = 0.07142857142857142\n",
            "Inferred class = Negative (-)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "!pip install textblob\n",
        "from textblob import TextBlob"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wyduiCNE_JT",
        "outputId": "34c7c16a-044d-4b4d-fb11-1df24d3920ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.7/dist-packages (0.15.3)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.7/dist-packages (from textblob) (3.7)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk>=3.1->textblob) (2022.6.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk>=3.1->textblob) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk>=3.1->textblob) (1.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk>=3.1->textblob) (4.64.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Task 3:\n",
        "\n",
        "def SentimentAnalyser(string):\n",
        "  \n",
        "  #for word in document:\n",
        "  # document[word] = word.lower()\n",
        "  \n",
        "  testimonial = TextBlob(string)\n",
        "  sentiment = testimonial.sentiment\n",
        "  polarity = sentiment[0]\n",
        "  subjectivity = sentiment[1] \n",
        "  \n",
        "  threshold = 0.15\n",
        "\n",
        "  if polarity > threshold:\n",
        "    Feedback = \"Positive Sentiment :)\"\n",
        "\n",
        "  elif polarity < -threshold:\n",
        "    Feedback = \"Negative Sentiment :(\"\n",
        "\n",
        "  else:\n",
        "    Feedback = \"Neutral Sentiment :|\"\n",
        "\n",
        "  print(\"string = \" + string + '\\n \\n')\n",
        "  print(Feedback)\n",
        "  print(\"Polarity= \" + str(polarity))\n",
        "  print(\"Subjectivity= \" + str(subjectivity))\n",
        "  print('------------------------------ \\n')\n",
        "  return\n"
      ],
      "metadata": {
        "id": "dGRGk1X3_QtG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SentimentAnalyser(\"NLP is cool\")\n",
        "SentimentAnalyser(\"NLP is cool and useful\")\n",
        "SentimentAnalyser(\"NLP is hard\")\n",
        "SentimentAnalyser(\"NLP is hard and useless\")\n",
        "SentimentAnalyser(\"NLP stands for natural language processing\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBcb4WDuIMEp",
        "outputId": "8eb677d8-bee5-4ee5-9f97-0e198cbddf3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "string = NLP is cool\n",
            " \n",
            "\n",
            "Positive Sentiment :)\n",
            "Polarity= 0.35\n",
            "Subjectivity= 0.65\n",
            "------------------------------ \n",
            "\n",
            "string = NLP is cool and useful\n",
            " \n",
            "\n",
            "Positive Sentiment :)\n",
            "Polarity= 0.32499999999999996\n",
            "Subjectivity= 0.325\n",
            "------------------------------ \n",
            "\n",
            "string = NLP is hard\n",
            " \n",
            "\n",
            "Negative Sentiment :(\n",
            "Polarity= -0.2916666666666667\n",
            "Subjectivity= 0.5416666666666666\n",
            "------------------------------ \n",
            "\n",
            "string = NLP is hard and useless\n",
            " \n",
            "\n",
            "Negative Sentiment :(\n",
            "Polarity= -0.39583333333333337\n",
            "Subjectivity= 0.37083333333333335\n",
            "------------------------------ \n",
            "\n",
            "string = NLP stands for natural language processing\n",
            " \n",
            "\n",
            "Neutral Sentiment :|\n",
            "Polarity= 0.1\n",
            "Subjectivity= 0.4\n",
            "------------------------------ \n",
            "\n"
          ]
        }
      ]
    }
  ]
}